# convolution neural network
## 资料内容
- [Leemeng-直观理解卷积神经网络](https://demo.leemeng.tw/cat-dog-classifier-prediction#gallery)
- [李宏毅教授CNN课程](https://www.youtube.com/watch?v=FrKWiRv254g)
### 笔记
- 本质上，任何类型的神经网络都是一个映射函数。其在内部进行一连串的数据转换步骤，把给定的输入数据转换为指定的输出形式。
- - 当然对于一个神经网络模型来说，转换目的可能不同，但都应该具有其转换的意义。
- 利用卷积运算来提取局部特征
- - 采用filter（滤波器3*3 stride为1）进行特征提取，把我们所需要提取的特征都设计出一个不同的filter。
- - filter为3*3 远小于图片的大小，目的是为了能够更有效率的提取特征，因为不同pattern可能出现在不同的位置以及pattern的大小可能与不尽相同。
- - 将第一组的filter得到的结果经过池化（pooling）后当做下一组filter的输入可以帮助我们提取新的特征（feature）
- - filter中的值不是人为设定的而是通过训练而得到的，这也是深度学习的一大特征即“**自动化特征工程**”
- - 池化运算，通常池化的滤波器都为2*2 stride为2。池化有很多种方式取值通常有均值或者最大值。通过池化可以对图片进行降低采样（downsampling）在不会改变图中的内容下降低了后面运算的数据量提取重要信息。加快了模型的训练速度
- - CNN中的卷积以及池化起到了萃取特征的作用，最后的全连接层扮演了分类器的作用（在CNN之前对于使用神经网络通常是一个特征与比如图片上的全部pixel都有关即都全连接，这就对信息的处理特别冗长而CNN其实每一块的信息提取只与3*3这块地方内的有联系。）
- 漂移学习（Transfer Learning 站在巨人的肩膀上）
- - 对于已经训练好的预训练模型直接拿来使用
- 对于深度学习就是一个咨讯提炼的管道、过程，把数据通过不断的筛选，留下最重要的咨讯，通过对重要咨讯的判断处理来帮助完成一些智能任务。（类似于人类学习世界的方式）
